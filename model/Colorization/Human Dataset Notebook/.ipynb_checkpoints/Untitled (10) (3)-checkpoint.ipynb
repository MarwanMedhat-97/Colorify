{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LeV3pw34K4wq"
   },
   "source": [
    "# Imports\n",
    "\n",
    "important notes \\n\n",
    "1-USE JUPYTER NOT JUPYTERLAB\n",
    "2-to enable tf 2.0\n",
    "you can go to the Conda tab (on Jupyter and not JupyterLab) and select the tensorflow_p36 environment. On the bottom left, you can search \"tensorflow\" in the available Conda packages. There will be a TF2.0 option. Check that box, and the click on the right arrow, which will install TF2.0 into your tensorflow_p36 environment.\n",
    "3- use the conda_tensorflow_p36 kernel\n",
    "Restart any existing notebooks that are open.\n",
    "\n",
    "Note: This works only with Jupyter and not JupyterLab.\n",
    "3-use tf 2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip         # pip 19.0 or higher is required for TF 2\n",
    "!pip install --upgrade setuptools  # Otherwise you'll get annoying warnings about bad installs\n",
    "!pip install --user --upgrade tensorflow==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7kl0HGupLFuv",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "#CNN Layers\n",
    "from tensorflow.keras.layers import Conv2D,Conv2DTranspose,Dropout,Input,BatchNormalization,GlobalAveragePooling2D,concatenate\n",
    "#Activations\n",
    "from tensorflow.keras.layers import ReLU,LeakyReLU\n",
    "from tensorflow.keras.activations import tanh,sigmoid\n",
    "#save and load\n",
    "from tensorflow.keras.models import save_model,load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from PIL import Image\n",
    "from tensorflow.keras import initializers\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "# !!! DONT USE CV2 IMAGE FUNCTIONS AT ALL USE IMAGE LIBRARY AND PLT.IMSHOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FGC97Cb8O3cc",
    "outputId": "fb37eeae-96b4-4dd9-8748-096886b8949e",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check version to be 2.0.0 exactly\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RbfT41JBLG37"
   },
   "source": [
    "# Setting Random Seed and Gpu Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uLubtN2iLPib",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = .23\n",
    "# \"\"\"\n",
    "# RandSeed = np.random.randint(0,1000)\n",
    "# np.random.seed(RandSeed)\n",
    "# tf.random.set_seed(RandSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path Variables and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wWWsARMMknaW",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PathDataset = 'kaggle/'  #change dir to your project folder\n",
    "# PathDatasetFood=\"kaggle/gantraintest/food\"\n",
    "PathTrainColorImagesOriginal=\"images/\"\n",
    "PathTrainColorImagesResized=\"train_rgb_resized/\"\n",
    "PathTrainGrayImagesResied=\"train_gray_resized/\"\n",
    "\n",
    "PathTestColorImagesOriginal=\"test/\"\n",
    "PathTestGrayImagesResied=\"test_gray_resized/\"\n",
    "\n",
    "PathProgressImages=\"ProgessCheckImages/\"\n",
    "\n",
    "# PathGeneratorCheckPoints=\"GeneratorCheckpoints/\"\n",
    "# PathDiscCheckPoints=\"DiscriminatorCheckpoints/\"\n",
    "# PathGanCheckPoints=\"GanCheckpoints/\"\n",
    "\n",
    "PathGeneratorAll=\"GeneratorModelAll/\"\n",
    "PathDiscAll=\"DiscriminatorModelAll/\"\n",
    "PathGanAll=\"GanModelAll/\"\n",
    "\n",
    "PathGeneratorWeights=\"GeneratorWeights/\"\n",
    "PathDiscriminatorWeights=\"DiscriminatorWeights/\"\n",
    "PathGanWeights=\"GanWeights/\"\n",
    "\n",
    "PathPerformanceFiles=\"Performance/\"\n",
    "\n",
    "#ONLY CURRENTLY\n",
    "os.chdir(PathDataset)  #change dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RxACmV2cLO_6"
   },
   "source": [
    "# Utility Functions Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DownloadFile(url):\n",
    "    '''\n",
    "    Downloads the file of a given url\n",
    "    '''\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def DisplayImages(Images,NumColumns=2,SubPlot=False,SubPlotSize=False):\n",
    "    #Denormalize Images from -1,1 to 0,255 to be displayed correctly\n",
    "    Images = (np.array(Images,dtype='float32')*127.5)+127.5\n",
    "    Images = np.array(Images,dtype='int32')\n",
    "#     print(Images)\n",
    "#     plt.imshow(Images[0])\n",
    "#     plt.show()\n",
    "    if SubPlot and SubPlotSize:\n",
    "        f, a = plt.subplots(int(len(Images)/NumColumns),NumColumns,figsize=SubPlotSize)\n",
    "    else:\n",
    "        f,a = plt.subplots(int(len(Images)/2),2,figsize=(20,20))\n",
    "    a = a.flatten()\n",
    "    i=0\n",
    "    for img in Images:\n",
    "#         a[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        a[i].imshow(img)\n",
    "\n",
    "        a[i].axis('off')\n",
    "        i=i+1\n",
    "    #plt.subplots_adjust(left=1,right=2,bottom=0.1,top=2,wspace=.1, hspace=.1)\n",
    "    #plt.subplots_adjust(wspace=.1, hspace=.1)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DisplayImagesSideBySide(Images1,Images2,Images3,NumColumns=2,SubPlot=False,SubPlotSize=False):\n",
    "    #Denormalize Images from -1,1 to 0,255 to be displayed correctly\n",
    "    Images1 = (np.array(Images1,dtype='float32')*127.5)+127.5\n",
    "    Images1 = np.array(Images1,dtype='int32')\n",
    "    Images2 = (np.array(Images2,dtype='float32')*127.5)+127.5\n",
    "    Images2 = np.array(Images2,dtype='int32')\n",
    "    Images3 = (np.array(Images3,dtype='float32')*127.5)+127.5\n",
    "    Images3 = np.array(Images3,dtype='int32')\n",
    "#     print(Images)\n",
    "#     plt.imshow(Images[0])\n",
    "#     plt.show()\n",
    "    if SubPlot and SubPlotSize:\n",
    "        f, a = plt.subplots(int(len(Images1)*3/NumColumns),NumColumns,figsize=SubPlotSize)\n",
    "    else:\n",
    "        f,a = plt.subplots(int(len(Images1)*3/3),3,figsize=(20,20))\n",
    "    a = a.flatten()\n",
    "    i=0\n",
    "    for img1,img2,img3 in zip(Images1,Images2,Images3):\n",
    "#         a[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        a[i].imshow(img1)\n",
    "        a[i].axis('off')\n",
    "        i=i+1\n",
    "        a[i].imshow(img2)\n",
    "        a[i].axis('off')\n",
    "        i=i+1\n",
    "        a[i].imshow(img3)\n",
    "        a[i].axis('off')\n",
    "        i=i+1\n",
    "    plt.subplots_adjust(left=1,right=2,bottom=0.1,top=2,wspace=.1, hspace=.1)\n",
    "    #plt.subplots_adjust(wspace=.1, hspace=.1)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def GetTrainImagePaths(PathColor=PathTrainColorImagesResized,PathGray=PathTrainGrayImagesResied):\n",
    "    PathColorImgs= glob.glob(PathColor+'/*.jpg')\n",
    "    PathColorImgs.sort()\n",
    "    PathGrayImgs= glob.glob(PathGray+'/*.jpg')\n",
    "    PathGrayImgs.sort()\n",
    "    return PathColorImgs,PathGrayImgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def GetTestImagePaths(PathGrayTest=PathTestGrayImagesResied,PathTestOriginal=PathTestColorImagesOriginal):\n",
    "#     PathGrayImgs= glob.glob(PathGrayTest+'/*.jpg')\n",
    "#     PathGrayImgs.sort()\n",
    "#     PathOriginal= glob.glob(PathTestOriginal+'/*.jpg')\n",
    "#     PathOriginal.sort()\n",
    "#     return PathGrayImgs,PathOriginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6RR4XXtFLVlb",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def GenerateProgessImages(ColorImgPaths,GrayImgPaths,NumProgessImages,NumTotalImages):\n",
    "    indexes=np.random.randint(0,NumTotalImages-1,NumProgessImages)\n",
    "  \n",
    "    ProgressColorImg = []\n",
    "    ProgressGrayImg = []\n",
    "    \n",
    "    for idx in indexes:\n",
    "        ProgressColorImg.append(np.array(Image.open(ColorImgPaths[idx]).convert('RGB')))\n",
    "        ProgressGrayImg.append(np.array(Image.open(GrayImgPaths[idx]).convert('RGB')))\n",
    "      #  print(ColorImgPaths[idx])\n",
    "       # print(GrayImgPaths[idx])\n",
    "    ProgressColorImg = (np.array(ProgressColorImg,dtype='float32')-127.5)/127.5\n",
    "    ProgressGrayImg = (np.array(ProgressGrayImg,dtype='float32')-127.5)/127.5\n",
    "    \n",
    "#     for img in ProgressColorImg:\n",
    "#         plt.imshow(img)\n",
    "#         cv2.imshow('',img)\n",
    "    #DONT USE CV2.IMSHOW IN AWS IT CRASHES THE KERNEL\n",
    "    #use plt.imshow()\n",
    "\n",
    "    return ProgressColorImg,ProgressGrayImg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DpkGmhIwv9mf"
   },
   "outputs": [],
   "source": [
    "def GenerateRealImages(ColorImgPath,GrayImgPath,NumImages):\n",
    "    indexes=np.random.randint(0,int(len(ColorImgPath))-1,NumImages)\n",
    "\n",
    "    ColorArr= []\n",
    "    GrayArr=[]\n",
    "\n",
    "    for idx in indexes:\n",
    "#         ColorArr.append(np.array(cv2.imread(ColorImgPath[idx])))\n",
    "#         GrayArr.append(np.array(cv2.imread(GrayImgPath[idx])))\n",
    "        ColorArr.append(np.array(Image.open(ColorImgPath[idx]).convert('RGB')))\n",
    "        GrayArr.append(np.array(Image.open(GrayImgPath[idx]).convert('RGB')))\n",
    "\n",
    "    ColorArr = (np.array(ColorArr,dtype='float32')-127.5)/127.5\n",
    "    GrayArr = (np.array(GrayArr,dtype='float32')-127.5)/127.5\n",
    "        \n",
    "    LabelReal = np.ones(shape=(NumImages,1))\n",
    "    \n",
    "    return ColorArr,GrayArr,LabelReal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZMnxj6C3wYRF",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def GenerateFakeGeneratorImages(GeneratorModel,GrayImagesPath,NumImages):\n",
    "    indexes=np.random.randint(0,int(len(GrayImagesPath))-1,NumImages)\n",
    "    GrayArr=[]\n",
    "\n",
    "    for idx in indexes:\n",
    "        Img = np.array(Image.open(GrayImagesPath[idx]).convert('RGB'))\n",
    "        GrayArr.append(Img)\n",
    "        \n",
    "\n",
    "    GrayArr = (np.array(GrayArr,dtype='float32')-127.5)/127.5\n",
    "    \n",
    "    GenColorArr=GeneratorModel.predict(GrayArr)\n",
    "                           \n",
    "    GenColorArr = np.array(GenColorArr,dtype='float32')\n",
    "    LabelFake = np.zeros(shape=(NumImages,1))\n",
    "    #print(\"!!!! gencolorarr{}\".format(GenColorArr.shape))\n",
    "    #print(\"!!!! grayarr{}\".format(GrayArr.shape))\n",
    "    return GenColorArr,GrayArr,LabelFake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#untested yet\n",
    "#!!!!!!!!NOT NEEDED CAN PASS FULL ARRAY TO GENERATOR TO PREDICT EACH ELEMENT\n",
    "# def GeneratorCheckProgressImages(GeneratorModel,ProgressArr,NumImages):\n",
    "\n",
    "#     GenColorArr= []\n",
    "\n",
    "#     for idx in indexes:\n",
    "#         GenColorArr.append(np.array(ProgressArr[i]))\n",
    "#     GenColorArr=np.array(GenColorArr,dtype='float32')\n",
    "#     return GenColorArr\n",
    "# new = Generator(ProgressColorImages)\n",
    "# new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1wf0kwEBv9xP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def SavePerformance(PerformanceFilePath,EpochNumber,DiscRealLoss,DiscFakeLoss,GeneratorLoss):\n",
    "    file = open(PerformanceFilePath+'Performance.txt', \"a\")\n",
    "    file.write(\"\\nEpoch Number {} , DiscRealLoss:{},DiscFakeLoss:{},GeneratorLoss:{}%\".format(EpochNumber,DiscRealLoss,\\\n",
    "                                                                                               DiscFakeLoss,GeneratorLoss))\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TlnS_1Olv93l",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def SaveAndDisplayEpochResults(SavePath,Images1,Images2,Images3,EpochNumber):\n",
    "    \n",
    "  \n",
    "#     f,a = plt.subplots(int(len(ImgArr)/2),2,figsize=(20,20))\n",
    "#     a = a.flatten()\n",
    "#     i=0\n",
    "#     for img in ImgArr:\n",
    "#         a[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "#         a[i].axis('off')\n",
    "#         i=i+1\n",
    "#     plt.subplots_adjust(wspace=.1, hspace=.1)\n",
    "#     plt.axis('off')\n",
    "#     f.savefig(SavePath+\"Epoch-{}.png\".format(EpochNumber))\n",
    "\n",
    "#Denormalize Images from -1,1 to 0,255 to be displayed correctly\n",
    "    Images1 = (np.array(Images1,dtype='float32')*127.5)+127.5\n",
    "    Images1 = np.array(Images1,dtype='int32')\n",
    "    Images2 = (np.array(Images2,dtype='float32')*127.5)+127.5\n",
    "    Images2 = np.array(Images2,dtype='int32')\n",
    "    Images3 = (np.array(Images3,dtype='float32')*127.5)+127.5\n",
    "    Images3 = np.array(Images3,dtype='int32')\n",
    "#     print(Images)\n",
    "#     plt.imshow(Images[0])\n",
    "#     plt.show()\n",
    "    \n",
    "    f,a = plt.subplots(int(len(Images1)*3/3),3,figsize=(20,20))\n",
    "    a = a.flatten()\n",
    "    i=0\n",
    "    for img1,img2,img3 in zip(Images1,Images2,Images3):\n",
    "#         a[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        a[i].imshow(img1)\n",
    "        a[i].axis('off')\n",
    "        i=i+1\n",
    "        a[i].imshow(img2)\n",
    "        a[i].axis('off')\n",
    "        i=i+1\n",
    "        a[i].imshow(img3)\n",
    "        a[i].axis('off')\n",
    "        i=i+1\n",
    "    plt.subplots_adjust(left=0.1,right=1,bottom=0.1,top=1,wspace=.1, hspace=.1)\n",
    "    #plt.subplots_adjust(wspace=.1, hspace=.1)\n",
    "    plt.axis('off')\n",
    "    f.savefig(SavePath+\"Epoch-{}.png\".format(EpochNumber))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "crLL0iSfhc9Q"
   },
   "source": [
    "# Loss Functions Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8jyREvwhe8k",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "########## VGG16 ###############\n",
    "*VGG16 is a image classification network trained on imagenet 14M images belonging to 1000 classes\n",
    "*it's input is 224,224,3 !THAT'S WHY K.RESIZE(224......)\n",
    "*the loss is taken from the 4th layer whose output is 28*28*512\n",
    "\n",
    "############ LOSSES #############\n",
    "\n",
    "#### 1) Feature level loss ####\n",
    "\n",
    "\n",
    "The second loss that we use is FeatureLevel loss i.e L2 distance between the activation(φj)\n",
    "of the 4th layer of the 16-layer VGG network (VGG16) pre-trained on the ImageNet dataset \n",
    "to retain high-level features like specific colors to objects and shapes\n",
    "\n",
    "### 2)Total Variation loss ####\n",
    "TotalVariation loss  is such that the GAN produces similar colors\n",
    "that were used for sketch-color image pairs in the training data.\n",
    "\n",
    "\n",
    "### 3)pixel level loss #####\n",
    "\n",
    "The first loss that we use is PixelLevel loss i.e L1 \n",
    "distance between each pixel of target color image and generated color image as,\n",
    "\n",
    "Custom loss for Pixel2Pixel level translation so that colors don't \n",
    "come out the edges of generated images.\n",
    "\n",
    "\n",
    "***weights \n",
    "pixel level -> 100\n",
    "feature loss -> 0.1\n",
    "total var. -> 0.0001\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "pixelLevelLoss_weight=100\n",
    "totalVariationLoss_weight=.0001\n",
    "featureLevelLoss_weight=.01\n",
    "\n",
    "def featureLevel_loss(y, g): \n",
    "  def finalFLoss(y_true, y_pred):\n",
    "    return K.mean( K.sqrt( K.sum( K.square( y - g ) ) ) )\n",
    "  \n",
    "  return finalFLoss\n",
    "\n",
    "def totalVariation_loss(y, g):\n",
    "\n",
    "  def finalTVLoss(y_true, y_pred):\n",
    "    return K.abs( K.sqrt( K.sum(K.square(g[:, 1:, :, :] - g[:, :-1, :, :])) + K.sum(K.square(g[:, :, 1:, :] - g[:, :, :-1, :])) ) )\n",
    "    # return K.mean( K.abs( K.sqrt( K.square(g[:, :-1, :-1, :] - g[:, 1:, :-1, :]) + K.square(g[:, :-1, :-1, :] - g[:, :-1, 1:, :]) ) ) )\n",
    "  \n",
    "  return finalTVLoss\n",
    "\n",
    "def pixelLevel_loss(y, g):\n",
    "\n",
    "  def finalPLoss(y_true, y_pred):\n",
    "    return K.mean( K.abs( y - g ) )\n",
    "  \n",
    "  return finalPLoss\n",
    "\n",
    "\n",
    "def binaryCrossEntropy(from_logits=False):\n",
    "  \n",
    "  def finalBCELoss(y_true, y_pred):\n",
    "    return  K.mean(K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n",
    "  \n",
    "  return finalBCELoss\n",
    "\n",
    "def ColorizationLoss(y,g,from_logits=False):\n",
    "    def colorloss(y_true,y_pred):\n",
    "\n",
    "        featurelevel =  K.mean( K.sqrt( K.sum( K.square( y - g ) ) ) )\n",
    "        totalvar =  K.abs( K.sqrt( K.sum(K.square(g[:, 1:, :, :] - g[:, :-1, :, :])) + K.sum(K.square(g[:, :, 1:, :] - g[:, :, :-1, :])) ) )\n",
    "        pixellevel = K.mean( K.abs( y - g ) )\n",
    "        binarycrossentropy = K.mean(K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n",
    "\n",
    "        return pixelLevelLoss_weight * pixellevel + totalVariationLoss_weight* totalvar + featureLevelLoss_weight * featurelevel\n",
    "    \n",
    "    return colorloss\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# lambda y_true, y_pred : tf.keras.losses.binary_crossentropy(y_true, y_pred) + \\\n",
    "#                                              pixelLevelLoss_weight * pixelLevelLoss(y_true, y_pred) + \\\n",
    "#                                              totalVariationLoss_weight * totalVariationLoss(y_true, y_pred) + \\\n",
    "#                                              featureLevelLoss_weight * featureLevelLoss(y_true, y_pred),\\\n",
    "\n",
    "# def CustomLossFnc(y_true,y_pred,from_logits=False):\n",
    "#     pixelLevelLoss_weight=100\n",
    "#     totalVariationLoss_weight=.0001\n",
    "#     featureLevelLoss_weight=.01\n",
    "#     pixelLevelLoss = K.mean( K.sqrt( K.sum( K.square( y_true - y_pred ) ) ) )\n",
    "#     totalVariationLoss     = K.abs( K.sqrt( K.sum(K.square(y_pred[:, 1:, :, :] - y_pred[:, :-1, :, :])) + K.sum(K.square(y_pred[:, :, 1:, :] - y_pred[:, :, :-1, :])) ) )\n",
    "#     featureLevelLoss     = K.mean( K.abs( y_true - y_pred ) )\n",
    "\n",
    "#     FinalLoss = tf.keras.losses.binary_crossentropy(y_true, y_pred) + \\\n",
    "#                                              pixelLevelLoss_weight * pixelLevelLoss + \\\n",
    "#                                              totalVariationLoss_weight * totalVariationLoss + \\\n",
    "#                                              featureLevelLoss_weight * featureLevelLoss\n",
    "#     return FinalLoss\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2LfhxU_3LVt6"
   },
   "source": [
    "# Gan Definition Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z8MTpHR2Latk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#redo\n",
    "def ConvLayer(ConvIn,NumFilters,FilterSize=4,StrideLength=2,DropOutRate=False,Activation=True,BatchNormalizationON=True,Padding=\"same\",Alpha=0.2):\n",
    "    WeightsInitializer = initializers.TruncatedNormal(mean=0.0, stddev=0.02,seed=None)  \n",
    "    Layer = Conv2D(NumFilters,FilterSize,StrideLength,padding=Padding,kernel_initializer=WeightsInitializer)(ConvIn)\n",
    "    if BatchNormalizationON:\n",
    "        Layer= BatchNormalization()(Layer)\n",
    "\n",
    "    if Activation:\n",
    "        Layer=LeakyReLU(alpha=Alpha)(Layer)\n",
    "\n",
    "\n",
    "    print(Layer.shape)\n",
    "    return Layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!!!!! GOOGLE PADDING SAME VS VALID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Anm30e7YU8Ri",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#redo\n",
    "def ConvTransLayer(ConvTransIn,NumFilters,FilterSize=4,StrideLength=2,DropOutRate=False,convOut=None,Activation=True,BatchNormalizationON=True,Padding=\"same\",Alpha=0.2):\n",
    "    WeightsInitializer = initializers.TruncatedNormal(mean=0.0, stddev=0.02,seed=None)   \n",
    "    Layer = Conv2DTranspose(NumFilters,FilterSize,StrideLength,padding='same',kernel_initializer=WeightsInitializer)(concatenate([ConvTransIn, convOut]) if convOut is not None else ConvTransIn)\n",
    "\n",
    "    if BatchNormalizationON:\n",
    "        Layer= BatchNormalization()(Layer)\n",
    "    if Activation:\n",
    "        Layer=LeakyReLU(alpha=Alpha)(Layer)\n",
    "    if DropOutRate:\n",
    "        Layer=Dropout(rate=DropOutRate)(Layer)\n",
    "    print(Layer.shape)\n",
    "    return Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kjPFkcmFU-m2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#redo\n",
    "def CreateGenerator(DropOut,Alpha,InputShape=(512,512,3)):\n",
    "  GeneratorInput = Input(InputShape)\n",
    "\n",
    "  NumFiltersGenerator=16\n",
    "\n",
    "  ConvLayerOut1=ConvLayer(GeneratorInput,NumFilters=NumFiltersGenerator,BatchNormalizationON=False,Alpha=Alpha)\n",
    "  ConvLayerOut2=ConvLayer(ConvLayerOut1,NumFilters=NumFiltersGenerator*2,Alpha=Alpha)\n",
    "  ConvLayerOut3=ConvLayer(ConvLayerOut2,NumFilters=NumFiltersGenerator*4,Alpha=Alpha)\n",
    "  ConvLayerOut4=ConvLayer(ConvLayerOut3,NumFilters=NumFiltersGenerator*8,Alpha=Alpha)\n",
    "  ConvLayerOut5=ConvLayer(ConvLayerOut4,NumFilters=NumFiltersGenerator*8,Alpha=Alpha)\n",
    "  ConvLayerOut6=ConvLayer(ConvLayerOut5,NumFilters=NumFiltersGenerator*8,Alpha=Alpha)\n",
    "  ConvLayerOut7=ConvLayer(ConvLayerOut6,NumFilters=NumFiltersGenerator*8,Alpha=Alpha)\n",
    "  ConvLayerOut8=ConvLayer(ConvLayerOut7,NumFilters=NumFiltersGenerator*8,Alpha=Alpha) \n",
    "\n",
    "\n",
    "    \n",
    "  ConvTransOut1=ConvTransLayer(ConvLayerOut8,NumFiltersGenerator*8,Alpha=Alpha)\n",
    "  ConvTransOut2=ConvTransLayer(ConvTransOut1,NumFiltersGenerator*8,convOut=ConvLayerOut7,DropOutRate=DropOut,Alpha=Alpha)\n",
    "  ConvTransOut3=ConvTransLayer(ConvTransOut2,NumFiltersGenerator*8,convOut=ConvLayerOut6,DropOutRate=DropOut,Alpha=Alpha)\n",
    "  ConvTransOut4=ConvTransLayer(ConvTransOut3,NumFiltersGenerator*8,convOut=ConvLayerOut5,DropOutRate=DropOut,Alpha=Alpha)\n",
    "  ConvTransOut5=ConvTransLayer(ConvTransOut4,NumFiltersGenerator*4,convOut=ConvLayerOut4,Alpha=Alpha)\n",
    "  ConvTransOut6=ConvTransLayer(ConvTransOut5,NumFiltersGenerator*2,convOut=ConvLayerOut3,Alpha=Alpha)\n",
    "  ConvTransOut7=ConvTransLayer(ConvTransOut6,NumFiltersGenerator,convOut=ConvLayerOut2,Alpha=Alpha)\n",
    "#   ConvTransOut8=ConvTransLayer(ConvTransOut7,NumFiltersGenerator,Alpha=Alpha) #bn false #activation false\n",
    "  ConvTransOut8=ConvTransLayer(ConvTransOut7,3,convOut=ConvLayerOut1,Activation=False,BatchNormalizationON=False,Alpha=Alpha) #bn false #activation false\n",
    "\n",
    "\n",
    "  GenOut = tanh(ConvTransOut8)\n",
    "\n",
    "  return Model(inputs=GeneratorInput,outputs=GenOut)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "6Ih_vnT8Wxxy",
    "outputId": "022847b2-e6e7-4af5-f678-192b8fc733cb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#redo\n",
    "def CreateDiscriminator(Alpha,InputShape=(512,512,3)):\n",
    "  \n",
    "  NumFiltersDiscriminator=16\n",
    "    \n",
    "#   DiscIn=Input(InputShape)\n",
    "\n",
    "  inp1 = Input(InputShape) # sketch input\n",
    "  inp2 = Input(InputShape) # colored input\n",
    "\n",
    "  inp = concatenate([inp1, inp2]) # 512x512x6\n",
    "  ConvLayerOut1=ConvLayer(inp,NumFilters=NumFiltersDiscriminator,BatchNormalizationON=False)\n",
    "  ConvLayerOut2=ConvLayer(ConvLayerOut1,NumFilters=NumFiltersDiscriminator*2)\n",
    "  ConvLayerOut3=ConvLayer(ConvLayerOut2,NumFilters=NumFiltersDiscriminator*4)\n",
    "  ConvLayerOut4=ConvLayer(ConvLayerOut3,NumFilters=NumFiltersDiscriminator*8)\n",
    "  ConvLayerOut5=ConvLayer(ConvLayerOut4,NumFilters=NumFiltersDiscriminator*8,FilterSize=2,StrideLength=1,Padding='valid')\n",
    "  ConvLayerOut6=ConvLayer(ConvLayerOut5,NumFilters=1,FilterSize=2,StrideLength=1,Padding='valid',Activation=False,BatchNormalizationON=False)\n",
    "  \n",
    "  ActvLayer = sigmoid(ConvLayerOut6)\n",
    "\n",
    "  DiscOut=GlobalAveragePooling2D()(ActvLayer)\n",
    "    \n",
    "  Discriminator = Model(inputs=[inp1, inp2],outputs=DiscOut)\n",
    "  Optimizer= Adam(lr=0.0002,beta_1=0.5)\n",
    "  Discriminator.compile(loss='binary_crossentropy',optimizer=Optimizer,metrics=['accuracy'])\n",
    "  return Discriminator\n",
    "\n",
    "#same \n",
    "  #last 2 stride 1 filter size =2 and padding valid\n",
    "  # no bn in first and last \n",
    "  #sigmoid actv. then pooling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom = {'custom_loss2':11111}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11111"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom['custom_loss2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'resize_1/ResizeNearestNeighbor:0' shape=(None, 224, 224, 3) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.resize_images(Input((512,512,3)), 224, 224, 'channels_last')\n",
    "tf.image.resize(Input((512,512,3)), (224, 224), tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ZAeTR0_Lr9U"
   },
   "source": [
    "# Gan Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qA82garfWx7r",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def CreateGan(DiscriminatorModel,GeneratorModel):\n",
    "\n",
    "    InputShape= (512,512,3)\n",
    "    \n",
    "    DiscriminatorModel.trainable= True\n",
    "    #Vgg Models\n",
    "    vgg_net1 = Model(inputs=vgg.input, outputs=ReLU()(vgg.get_layer('block2_conv2').output))\n",
    "    vgg_net2 = Model(inputs=vgg.input, outputs=ReLU()(vgg.get_layer('block2_conv2').output))\n",
    "    \n",
    "    pixelLevelLoss_weight=100\n",
    "    totalVariationLoss_weight=.0001\n",
    "    featureLevelLoss_weight=.01\n",
    "\n",
    "\n",
    "    #generator\n",
    "    GrayInput = Input(InputShape)\n",
    "    GenOutColorImage = GeneratorModel([GrayInput])\n",
    "    OriginalColorImage = Input(InputShape)\n",
    "    #to train Generator  only \n",
    "#     DiscriminatorModel.trainable=False\n",
    "\n",
    "    \n",
    "    #print(concatenate([GrayInput,GenOutColorImage]))\n",
    "    # ======= Discriminator ======= #\n",
    "    DiscriminatorOutput = DiscriminatorModel([GrayInput,GenOutColorImage])\n",
    "    OriginalColorImage = Input(InputShape)\n",
    "\n",
    "\n",
    "    # =================== PixelLevel Loss =================== #\n",
    "    pixelLevelLoss = pixelLevel_loss(OriginalColorImage,GenOutColorImage)\n",
    "\n",
    "    # =================== TotalVariation Loss =================== #\n",
    "    totalVariationLoss = totalVariation_loss(OriginalColorImage,GenOutColorImage)\n",
    "\n",
    "    # =================== FeatureLevel Loss =================== # \n",
    "    # Output dimensions must be positive keras backend resize_images : https://stackoverflow.com/a/57218765/9079093\n",
    "\n",
    "    # K.resize_images(color_inp, .4375, .4375, 'channels_last', 'bilinear')\n",
    "    net1_outp = vgg_net1([tf.image.resize(OriginalColorImage, (224, 224), tf.image.ResizeMethod.BILINEAR)])\n",
    "\n",
    "    # K.resize_images(gen_color_output, .4375, .4375, 'channels_last', 'bilinear') \n",
    "    net2_outp = vgg_net2([tf.image.resize(GenOutColorImage, (224, 224), tf.image.ResizeMethod.BILINEAR)])\n",
    "\n",
    "    featureLevelLoss = featureLevel_loss(net1_outp,\\\n",
    "                                       net2_outp)\n",
    "\n",
    "    # =================== CrossEntropy Loss =================== #\n",
    "    crossEntropyLoss = binaryCrossEntropy()\n",
    "\n",
    "    # =================== Final Model =================== #\n",
    "    model = Model(inputs=[GrayInput,OriginalColorImage], outputs=DiscriminatorOutput)\n",
    "\n",
    "    opt = Adam(lr=.0002, beta_1=.5)\n",
    "\n",
    "    def custom_loss34(y_true,y_pred):\n",
    "        return tf.keras.losses.binary_crossentropy(y_true, y_pred) + \\\n",
    "                                             pixelLevelLoss_weight * pixelLevelLoss(y_true, y_pred) + \\\n",
    "                                             totalVariationLoss_weight * totalVariationLoss(y_true, y_pred) + \\\n",
    "                                             featureLevelLoss_weight * featureLevelLoss(y_true, y_pred),\\\n",
    "\n",
    "    print(custom['custom_loss2'])\n",
    "    custom['custom_loss2']=custom_loss34\n",
    "    print(\"HERERRRR\")\n",
    "    print(custom['custom_loss2'])\n",
    "    print(custom_loss34)\n",
    "    # Single output multiple loss functions in keras : https://stackoverflow.com/a/51705573/9079093\n",
    "    model.compile(loss=custom_loss34,optimizer=opt,experimental_run_tf_function=False)\n",
    "\n",
    "    return model\n",
    "# # =================== Final Model =================== #\n",
    "#     model = Model(inputs=[GrayInput, OriginalColorImage], outputs=DiscriminatorOutput)\n",
    "\n",
    "#     opt = Adam(lr=.0002, beta_1=.5)\n",
    "\n",
    "#     # Single output multiple loss functions in keras : https://stackoverflow.com/a/51705573/9079093\n",
    "#     model.compile(loss=ColorizationLoss,optimizer=opt,experimental_run_tf_function=False)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#     inp1 = np.random.randint(0,1000,(3,3,5)) # sketch input\n",
    "#     inp2 =np.random.randint(0,1000,(3,3,5))\n",
    "\n",
    "#     inp = concatenate([inp1, inp2]) # 512x512x6\n",
    "#     print(inp1)\n",
    "#     print(inp2)\n",
    "#     print(inp1.shape)\n",
    "#     print(inp2.shape)\n",
    "#     print(inp.shape)\n",
    "#     print(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "riBBDynKWyCi",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def TrainGan(GanModel,GeneratorModel,DiscriminatorModel,GrayImgPaths,ColorImagePaths,ProgressGrayImages,ProgressColorImages,NumEpochs,BatchSize,NumStartEpoch):\n",
    "     \n",
    "    NumBatches=int(len(GrayImgPaths)/BatchSize)\n",
    "    #file = open(PathPerformanceFiles+'Performancebatchtest.txt', \"a\")\n",
    "    \n",
    "    if NumStartEpoch > NumEpochs:\n",
    "        print(\"Please enter Start Number lower than total epochs !\")\n",
    "    for Epoch in range(NumStartEpoch,NumEpochs):\n",
    "        for Batch in range(NumBatches):\n",
    "            \n",
    "            #DiscriminatorModel.trainable=True\n",
    "            \n",
    "\n",
    "            if not Batch%2:\n",
    "                \n",
    "                #Generate real images \n",
    "                RealColorImages,RealGrayImages,LabelReal = GenerateRealImages(ColorImagePaths,GrayImgPaths,int(BatchSize/2))\n",
    "         \n",
    "            #Train Discriminator on real images\n",
    "                RealDiscriminitorLoss,_= DiscriminatorModel.train_on_batch([RealGrayImages,RealColorImages],LabelReal *.9)\n",
    "            \n",
    "            if not Batch%3:\n",
    "                             #Generate fake images\n",
    "                FakeColorImages,FakeRealGrayImages,LabelFake= GenerateFakeGeneratorImages(GeneratorModel,GrayImgPaths,int(BatchSize/2))\n",
    "            \n",
    "            #Train Discriminator on fake images\n",
    "                FakeDiscriminatorLoss,_ =DiscriminatorModel.train_on_batch([FakeRealGrayImages,FakeColorImages],LabelFake)\n",
    "            \n",
    "#             #avoids a warning\n",
    "#             DiscriminatorModel.trainable=False\n",
    "            \n",
    "        \n",
    "            \n",
    "            #Generate real images \n",
    "            RealColorImages,RealGrayImages,LabelReal = GenerateRealImages(ColorImagePaths,GrayImgPaths,int(BatchSize/2))\n",
    "         \n",
    "            GeneratorLoss = GanModel.train_on_batch([RealGrayImages,RealColorImages],LabelReal)\n",
    "            print(\"Epoch #{}/{} Batch #{}/{} RealDiscLoss:{},FakeDiscLoss:{},GeneratorLoss:{}\".format(Epoch+1,NumEpochs,Batch+1,NumBatches,RealDiscriminitorLoss,FakeDiscriminatorLoss,GeneratorLoss))\n",
    "     #       file.write(\"Epoch #{}/{} Batch #{}/{} RealDiscLoss:{},FakeDiscLoss:{},GeneratorLoss:{}\".format(Epoch+1,NumEpochs-NumStartEpoch,Batch+1,NumBatches,RealDiscriminitorLoss,FakeDiscriminatorLoss,GeneratorLoss))\n",
    "        \n",
    "        if Epoch % 3 == 0 :\n",
    "            #Save Models' weights only\n",
    "            SaveModelWeightsEpoch(Generator,PathGeneratorWeights,Epoch)\n",
    "            SaveModelWeightsEpoch(Discriminator,PathDiscriminatorWeights,Epoch)\n",
    "            SaveModelWeightsEpoch(Gan,PathGanWeights,Epoch)\n",
    "\n",
    "            #Test ProgressImages on Generator\n",
    "            ProgressGeneratorColored = GeneratorModel.predict(ProgressGrayImages)\n",
    "\n",
    "            #Display Progress Images after each epoch\n",
    "            #!!Don't enable display to speed up training just save figure and check it later\n",
    "            #DisplayImagesSideBySide(np.array(ProgressGeneratorColored),ProgressColorImages,ProgressGrayImages,3,True,(20,20))\n",
    "            #DisplayImages(ProgressColorImages,3,True,(20,20))\n",
    "\n",
    "\n",
    "\n",
    "            SaveAndDisplayEpochResults(PathProgressImages,np.array(ProgressGeneratorColored),np.array(ProgressColorImages),np.array(ProgressGrayImages),Epoch)\n",
    "        \n",
    "        SavePerformance(PathPerformanceFiles,Epoch,RealDiscriminitorLoss,FakeDiscriminatorLoss,GeneratorLoss)\n",
    "\n",
    "        #Clear Cell output after each epoch\n",
    "       # display.clear_output(True)\n",
    "    #file.close()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2XNjmhWWLayk"
   },
   "source": [
    "# Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YIPWgBHnLfhV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def SaveModelAllEpoch(Model,FilePath,EpochNumber):\n",
    "  Model.save(FilePath+\"Epoch-{}\".format(EpochNumber))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q9sexP8Vw0ts",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def SaveModelWeightsEpoch(Model,FilePath,EpochNumber):\n",
    "  FullPath=FilePath+\"Epoch-{}\".format(EpochNumber)\n",
    "  Model.save_weights(FullPath ,save_format='tf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zICAKhg1w7Fz",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def LoadModelAllEpoch(FilePath,EpochNumber):\n",
    "  return load_model(FilePath+\"Epoch-{}\".format(EpochNumber),custom_objects={'custom_loss34': custom['custom_loss2']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRY8AqRCw8De",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def LoadModelWeightsEpoch(Model,FilePath,EpochNumber):\n",
    "    Model.load_weights(FilePath+\"Epoch-{}\".format(EpochNumber))\n",
    "    return Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DJAUWHM7LfqW"
   },
   "source": [
    "# Setting Test or Create Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "segjH1RMLq6C",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TestMode=0\n",
    "# set to 0 for create a new model\n",
    "# set to 1 to load existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir kaggle\n",
    "os.chdir(\"kaggle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Downloading From URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DownloadFile(\"https://datasets.d2.mpi-inf.mpg.de/andriluka14cvpr/mpii_human_pose_v1.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "my_tar = tarfile.open('mpii_human_pose_v1.tar.gz')\n",
    "my_tar.extractall('./') # specify which folder to extract to\n",
    "my_tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('images')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(cv2.imread('040659054.jpg'))\n",
    "print(img.shape)\n",
    "plt.imshow(img[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"images/040659054.jpg\")\n",
    "plt.imshow(img[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nr12k6uvMkR5"
   },
   "source": [
    "# Dataset Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CjjO_WdlMnEr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -q kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!ls ~/.kaggle\n",
    "#!chmod 600 /root/.kaggle/kaggle.json  # set permission\n",
    "!kaggle datasets download -d kmader/food41 -p ./kaggle/gantraintest/food\n",
    "# os.chdir(PathDataset)  #change dir\n",
    "# !unzip -q beginner.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(PathDatasetFood)  #change dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -R food/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q food41.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mkdir train_rgb_resized\n",
    "!mkdir train_gray_resized\n",
    "!mkdir test_gray_resized\n",
    "!mkdir ProgessCheckImages\n",
    "!mkdir GeneratorCheckpoints\n",
    "!mkdir DiscriminatorCheckpoints\n",
    "!mkdir GanCheckpoints\n",
    "!mkdir GeneratorModelAll\n",
    "!mkdir DiscriminatorModelAll\n",
    "!mkdir GanModelAll\n",
    "!mkdir GeneratorWeights\n",
    "!mkdir DiscriminatorWeights\n",
    "!mkdir GanWeights\n",
    "!mkdir Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir train_rgb_resized\n",
    "!mkdir train_gray_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((glob.glob('images/*/*.jpg'))[600:1200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H4AOEH0TMnMk"
   },
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qmuGfjnbMpnK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def TrainPreprocessing():\n",
    "    i = 1\n",
    "    for image in glob.glob('images/*.jpg'):\n",
    "        img_path = image\n",
    "        img = cv2.imread(img_path)\n",
    "        print(i)\n",
    "        dim = (512, 512)\n",
    "        img = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        cv2.imwrite(\"train_rgb_resized/\"+str(i)+\".jpg\",img)\n",
    "        cv2.imwrite(\"train_gray_resized/\"+str(i)+\".jpg\",gray_img)\n",
    "        i+=1\n",
    "    \n",
    "\n",
    "TrainPreprocessing()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestPreprocessing():\n",
    "    i = 1\n",
    "    for image in glob.glob('test/*.jpg'):\n",
    "        img_path = image\n",
    "        img = cv2.imread(img_path)\n",
    "        print(i,'/6000')\n",
    "        dim = (512, 512)\n",
    "        img = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        cv2.imwrite(\"test_gray_resized/\"+str(i)+\".jpg\",gray_img)\n",
    "        i+=1\n",
    "\n",
    "TestPreprocessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha=.2 #leaky relu param\n",
    "learning_rate=.0002\n",
    "drop_rate=.5\n",
    "beta_1=.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "vgg = VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -R DiscriminatorWeights/*\n",
    "# !rm -R GeneratorWeights/*\n",
    "# !rm -R ProgessCheckImages/*\n",
    "# !rm -R GanWeights/*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Creation and Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/initializers.py:94: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "(?, 256, 256, 16)\n",
      "(?, 128, 128, 32)\n",
      "(?, 64, 64, 64)\n",
      "(?, 32, 32, 128)\n",
      "(?, 31, 31, 128)\n",
      "(?, 30, 30, 1)\n",
      "(?, 256, 256, 16)\n",
      "(?, 128, 128, 32)\n",
      "(?, 64, 64, 64)\n",
      "(?, 32, 32, 128)\n",
      "(?, 16, 16, 128)\n",
      "(?, 8, 8, 128)\n",
      "(?, 4, 4, 128)\n",
      "(?, 2, 2, 128)\n",
      "(?, 4, 4, 128)\n",
      "(?, 8, 8, 128)\n",
      "(?, 16, 16, 128)\n",
      "(?, 32, 32, 128)\n",
      "(?, 64, 64, 64)\n",
      "(?, 128, 128, 32)\n",
      "(?, 256, 256, 16)\n",
      "(?, 512, 512, 3)\n",
      "11111\n",
      "HERERRRR\n",
      "<function CreateGan.<locals>.custom_loss34 at 0x7fb85005c158>\n",
      "<function CreateGan.<locals>.custom_loss34 at 0x7fb85005c158>\n"
     ]
    }
   ],
   "source": [
    "Discriminator=CreateDiscriminator(.2)\n",
    "Generator=CreateGenerator(drop_rate,.2)\n",
    "Gan =CreateGan(Discriminator,Generator)\n",
    "\n",
    "# print(\"####Discriminitor Architecture####\")\n",
    "# Discriminator.summary()\n",
    "\n",
    "# print(\"####Generator Architecture####\")\n",
    "# Generator.summary()\n",
    "\n",
    "# print(\"####Gan Architecture####\")\n",
    "# Gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "htGIZN1BLvJC"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    # ColorImagePaths,GrayImgPaths =GetTrainImagePaths()\n",
    "\n",
    "    # ProgressColorImages,ProgressGrayImages = GenerateProgessImages(ColorImagePaths,GrayImgPaths,12,len(GrayImgPaths))\n",
    "    # print(ProgressColorImages.shape,ProgressGrayImages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ColorImagePaths,GrayImgPaths =GetTrainImagePaths()\n",
    "# FakeColorImages,FakeRealGrayImages,LabelFake= GenerateFakeGeneratorImages(Generator,GrayImgPaths,int(8/2))\n",
    "# print(FakeColorImages.shape,FakeRealGrayImages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V1dJJXANLyE5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ColorImagePaths,GrayImgPaths =GetTrainImagePaths()\n",
    "ProgressColorImages,ProgressGrayImages = GenerateProgessImages(ColorImagePaths,GrayImgPaths,12,len(GrayImgPaths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ColorImagePaths=ColorImagePaths[1000:2000]\n",
    "# GrayImgPaths=GrayImgPaths[1000:2000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24984,) (24984,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(ColorImagePaths).shape,np.array(GrayImgPaths).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BGR TO RGB DONT KNOW WHY ITS BGR \n",
    "arr = np.array(Generator.predict(ProgressGrayImages))\n",
    "for sub in range(len(arr)):\n",
    "    x = arr[sub]\n",
    "    x= x[:,:,::-1]\n",
    "    arr[sub] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DisplayImagesSideBySide(ProgressColorImages,np.array(Generator.predict(ProgressGrayImages)),ProgressGrayImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch #22/250 Batch #1/1249 RealDiscLoss:0.7563132047653198,FakeDiscLoss:8.176565170288086,GeneratorLoss:96.48939514160156\n",
      "Epoch #22/250 Batch #2/1249 RealDiscLoss:0.7563132047653198,FakeDiscLoss:8.176565170288086,GeneratorLoss:101.9013671875\n",
      "Epoch #22/250 Batch #3/1249 RealDiscLoss:1.1317654848098755,FakeDiscLoss:8.176565170288086,GeneratorLoss:84.49494171142578\n"
     ]
    }
   ],
   "source": [
    "TrainGan(Gan,Generator,Discriminator,GrayImgPaths,ColorImagePaths,ProgressGrayImages,ProgressColorImages,NumEpochs=250,BatchSize=20,NumStartEpoch=21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8aSItq3zLydU"
   },
   "source": [
    "# Testing and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "there is no objective loss function used to train the GAN generator models and \n",
    "no way to objectively assess the progress of the traini\n",
    "ng and the relative or absolute quality of the model from loss alone.\n",
    "\n",
    "!!Therefore cannot also use earlystopping callbacks with gans\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# concatenate([ProgressGrayImages,ProgressColorImages]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test=Generator.evaluate(ProgressGrayImages,ProgressColorImages) #Can't do this  on  tf 2.2.0\n",
    "Gan.evaluate([ProgressGrayImages,ProgressColorImages],[1]*12)\n",
    "#before train\n",
    "#341.7870178222656"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Gan.evaluate([ProgressGrayImages,ProgressColorImages],[1]*12)\n",
    "#after train\n",
    "#347.8662109375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DisplayImages(np.array(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YKWu1btRL62s",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = Generator.predict(ProgressGrayImages)\n",
    "#print(test)\n",
    "DisplayImages(np.array(test[:,:,::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rnO6bDN-L7PP"
   },
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6eQz1_7dMAfy",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Save All of the Model \n",
    "# SaveModelAllEpoch(Generator,PathGeneratorAll,0)\n",
    "# SaveModelAllEpoch(Discriminator,PathDiscAll,0)\n",
    "# SaveModelAllEpoch(Gan,PathGanAll,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Save Models' weights only\n",
    "SaveModelWeightsEpoch(Generator,PathGeneratorWeights,0)\n",
    "SaveModelWeightsEpoch(Discriminator,PathDiscriminatorWeights,0)\n",
    "SaveModelWeightsEpoch(Gan,PathGanWeights,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4tGQlDzvMBIG"
   },
   "source": [
    "# Load Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQEYKpTpMD6r",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Load Model all\n",
    "# Gan=LoadModelAllEpoch(PathGanAll,0)\n",
    "# Discriminator=LoadModelAllEpoch(PathDiscAll,0)\n",
    "# Generator=LoadModelAllEpoch(PathGeneratorAll,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load Model Weights only\n",
    "Gan=LoadModelWeightsEpoch(Gan,PathGanWeights,21)\n",
    "Discriminator=LoadModelWeightsEpoch(Discriminator,PathDiscriminatorWeights,21)\n",
    "Generator=LoadModelWeightsEpoch(Generator,PathGeneratorWeights,21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C7lVgIb1MGQJ"
   },
   "source": [
    "# Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pmxwar5qMfcs",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "changes\n",
    "1- predict instead of generator()\n",
    "2- image.open instead of imread\n",
    "3-np.ones((#,1)) insteadof np.ones((#))\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
